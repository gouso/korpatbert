{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "# 프로그램 목적 : KorPatBERT 와 Keras를 활용하여, 3개의 클래스로 문장을 분류하는 테스트 프로그램\n",
    "# 사용되어진 데이터 셋은 label, sentence 두개의 컬럼으로 구성되어 있으며,\n",
    "# 클래스별 300개씩 총 900개의 데이터로 이루어져 있다.\n",
    "# label은 특허 CPC코드 섹션 \"A\", \"B\", \"C\" 3개의 클래스로 구성되어 있고, \n",
    "# sentence 는 특허기술에 대한 문장으로 이루어져 있다.\n",
    "\n",
    "# 필요 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "import bert\n",
    "import os\n",
    "import mecab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tqdm import tqdm\n",
    "from korpat_tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/irteam/anaconda3/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/irteam/anaconda3/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tensorflow==2.2.0 in /home/irteam/anaconda3/lib/python3.7/site-packages (2.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/irteam/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (1.16.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /home/irteam/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/irteam/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /home/irteam/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (2.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/irteam/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (1.1.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/irteam/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (0.3.3)\n",
      "Requirement already satisfied: scipy==1.4.1 in /home/irteam/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (1.4.1)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /home/irteam/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (2.10.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/irteam/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (1.47.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/irteam/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (1.11.2)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /home/irteam/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (3.17.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /home/irteam/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/irteam/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (0.12.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/irteam/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (0.34.2)\n",
      "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /home/irteam/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (2.2.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /home/irteam/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /home/irteam/anaconda3/lib/python3.7/site-packages (from tensorflow==2.2.0) (1.19.5)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/irteam/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/irteam/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.30.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/irteam/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (59.5.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/irteam/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/irteam/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/irteam/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/irteam/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.25.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/irteam/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/irteam/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/irteam/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/irteam/anaconda3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/irteam/anaconda3/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.0.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/irteam/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/irteam/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/irteam/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2022.12.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/irteam/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/irteam/anaconda3/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/irteam/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/irteam/anaconda3/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/irteam/anaconda3/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.4.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/irteam/anaconda3/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/irteam/anaconda3/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/irteam/anaconda3/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/irteam/anaconda3/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow==2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert in /home/irteam/anaconda3/lib/python3.7/site-packages (2.2.0)\n",
      "Requirement already satisfied: erlastic in /home/irteam/anaconda3/lib/python3.7/site-packages (from bert) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 환경변수 설정\n",
    "os.environ['TF_KERAS'] = '1'    # Keras Tensorflow 설정\n",
    "config_path     = \"./pretrained/korpat_bert_config.json\" # KorpatBert Config 파일 경로\n",
    "vocab_path      = \"./pretrained/korpat_vocab.txt\"        # KorpatTokenizer Vocabulary 파일 경로\n",
    "checkpoint_path = \"./pretrained/model.ckpt-381250\"       # KorpatBert 모델파일 경로\n",
    "pretreind_model_dir = \"./pretrained/\"                    # KorpatBert 모델 디렉토리 경로\n",
    "dataset_path = \"./lm_test_data.tsv\"                      # 사용할 데이터셋 경로\n",
    "save_model_path = \"./korpat_bert_test_model.h5\"          # 학습완료 모델 저장 경로\n",
    "\n",
    "MAX_SEQ_LEN = 256 # 학습 최대 토큰 갯수\n",
    "BATCH_SIZE = 9    # 학습 배치 사이즈 기본8\n",
    "EPOCHS = 5        # 학습 에폭\n",
    "LR = 0.00003      # 학습률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분리 비율에 따른 데이터셋 분리 함수\n",
    "# 입력 : dataset(분리 대상 데이터셋), split_val(분리 비율)\n",
    "# 출력 : train_data(분리 데이터셋), dev_data(분리 데이터셋)\n",
    "def dataset_split(dataset, split_val):\n",
    "    lengths = int(len(dataset) * split_val)\n",
    "    train_data = dataset[:lengths]\n",
    "    dev_data = dataset[lengths:]\n",
    "    return train_data, dev_data\n",
    "\n",
    "# 데이터 셋 로드 함수\n",
    "# 입력 : dataset_url (전체 데이터셋 경로)\n",
    "# 출력 : train_data(학습데이터) dev_data(검증데이터), test_data(평가데이터)\n",
    "def dataset_load(dataset_url):\n",
    "    all_data = pd.read_csv(dataset_url, sep='\\t')\n",
    "    all_data = all_data.sample(frac=1).reset_index(drop=True)\n",
    "    train_data, test_data = dataset_split(dataset=all_data, split_val=0.9)\n",
    "    train_data, dev_data = dataset_split(dataset=train_data, split_val=0.9)\n",
    "\n",
    "    return train_data, dev_data, test_data\n",
    "\n",
    "# 학습을 위한 데이터 셋 전처리 함수\n",
    "# 입력 : dataset(전처리 대상 데이터셋)\n",
    "# 출력 : tokens(토큰화 결과), x_data(입력데이터), y_data(정답데이터)\n",
    "def preprocessing_dataset(dataset):\n",
    "    tokens, indices, labels = [], [],[]\n",
    "    \n",
    "    # 데이터셋의 문장을 토큰화 및 인코딩 처리하고, 라벨을 One hot 벡터 변환으로 처리한다.\n",
    "    for label, sentence in tqdm(zip(dataset['label'], dataset['sentence']), desc = \"데이터 전처리 진행중\"):\n",
    "        tokens.append(tokenizer.tokenize(sentence))\n",
    "        ids, _ = tokenizer.encode(sentence, max_len=MAX_SEQ_LEN)\n",
    "        indices.append(ids)\n",
    "\n",
    "        if label == \"A\":\n",
    "            labels.append([1, 0, 0])\n",
    "        elif label == \"B\":\n",
    "            labels.append([0, 1, 0])\n",
    "        else:\n",
    "            labels.append([0, 0, 1])\n",
    "\n",
    "    x_data = np.array(indices)\n",
    "    y_data = np.array(labels)\n",
    "    print(\"===> 전처리 결과 출력 <===\")\n",
    "    print(\"===> tokens sample : \", tokens[0])\n",
    "    print(\"===> indices sample : \", indices[0])\n",
    "    print(\"===> x_data shape : \", x_data.shape)\n",
    "    print(\"===> y_data shape : \", y_data.shape)\n",
    "    \n",
    "    return tokens, x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> 학습데이터 샘플 출력 및 전처리 시작 <===\n",
      "  label                                           sentence\n",
      "0     B  초음파 세척기 본 발명은 진동소자와 연계되어 진동을 일으키는 진동판의 대면적화를 통...\n",
      "1     A  미네랄볼을 이용한 산야초 발효촉진 방법 및 산야초 발효추출액 본 발명은 산야초 고유...\n",
      "2     B  신용카드 매출전표 본 발명은 신용카드 매출전표에 관한 것으로 더욱 상세하게는 세 장...\n",
      "3     A  탄산칼슘, 식품 첨가용 탄산칼슘 제제 및 식품 음료 등의 식품에 첨가했을 경우에, ...\n",
      "4     A  복합 발효 하수오 추출물과 한약재 추출물을 이용한 갱년기 증상 개선용 음료의 제조방...\n",
      "5     C  슬래그의 포밍 억제 방법 및 전로 정련 방법 전로의 하방에 설치한 배재 레이들로 노...\n",
      "6     B  사진첩 본 고안은 사진을 회전캡으로 회전시키면서 간단하게 보관이나 열람이 가능토록 ...\n",
      "7     C  표면 처리 금속판, 전지 용기 및 전지 금속판 및 상기 금속판 상에 형성된 니켈-코...\n",
      "8     A  영양소가 풍부한 기능성 두부 제조방법 본 발명은 영양소가 풍부한 기능성 두부 제조방...\n",
      "9     C  공배양 몰드, 공배양 방법 및 폐 장기 모사칩 본 발명에 따른 공배양 몰드는 중앙부...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "데이터 전처리 진행중: 729it [00:05, 132.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> 전처리 결과 출력 <===\n",
      "===> tokens sample :  ['[CLS]', '초음파', '세척기', '본', '발명', '은', '진동', '소자', '와', '연계', '되', '어', '진동', '을', '일으키', '는', '진동판', '의', '대', '면적', '화', '를', '통해', '세', '척', '효율', '을', '한층', '향상', '시킬', '수', '있', '는', '초음파', '세척기', '에', '관한', '것', '이', '다', '.', '본', '발명', '은', '하나', '또는', '복수', '개', '의', '단위', '진동자', '와', '대', '면적', '의', '진동판', '을', '가지', '는', '케이스', '의', '조합', '으로', '이루어진', '진동', '모듈', '을', '채택', '하', '여', '진동', '소자', '로부터', '발생', '되', '는', '진동', '파', '가', '다양', '한', '경로', '로', '전달', '될', '수', '있', '도록', '함', '과', '더불', '어', '진동', '의', '세기', '와', '강도', '를', '높일', '수', '있', '도록', '한', '새로운', '형태', '의', '진동', '방식', '을', '구현', '함', '으로써', ',', '적', '은', '수', '의', '진동자', '만', '으로', '도', '세', '척', '능력', '을', '크', '게', '높일', '수', '있', '는', '동시', '에', '제작', '비용', '절감', '에', '따라', '경제', '적', '으로', '도', '유리', '하', '고', ',', '소음', '발생', '문제', '를', '대폭', '개선', '할', '수', '있', '으며', ',', '제작', '및', '조립', '이', '쉬', '##울', '뿐', '만', '아니', '라', 'A', '/', 'S', '는', '물론', '유지', '보수', '및', '관리', '측면', '이나', '전체', '적', '인', '운용', '측면', '에서', '유리', '한', '점', '이', '있', '는', '초음파', '세척기', '를', '제공', '한다', '.', '[SEP]']\n",
      "===> indices sample :  [5, 2035, 11702, 58, 77, 32, 1154, 518, 47, 2256, 26, 39, 1154, 15, 4992, 11, 9112, 9, 68, 1904, 80, 16, 268, 171, 2088, 1044, 15, 8129, 751, 607, 24, 25, 11, 2035, 11702, 10, 439, 56, 13, 18, 14, 58, 77, 32, 178, 71, 365, 101, 9, 835, 8775, 47, 68, 1904, 9, 9112, 15, 392, 11, 1032, 9, 908, 33, 665, 1154, 486, 15, 6131, 12, 40, 1154, 518, 176, 274, 26, 11, 1154, 233, 22, 546, 21, 1013, 37, 587, 114, 24, 25, 118, 136, 55, 3945, 39, 1154, 9, 3339, 47, 1186, 16, 4021, 24, 25, 118, 21, 1763, 371, 9, 1154, 603, 15, 693, 136, 295, 8, 45, 32, 24, 9, 8775, 259, 33, 27, 171, 2088, 2641, 15, 308, 64, 4021, 24, 25, 11, 735, 10, 991, 1859, 3047, 10, 143, 3833, 45, 33, 27, 778, 12, 34, 8, 2959, 274, 576, 16, 7261, 1219, 62, 24, 25, 376, 8, 991, 44, 754, 13, 2553, 20776, 966, 259, 527, 197, 152, 148, 145, 11, 1641, 473, 4479, 44, 682, 667, 668, 690, 45, 53, 3322, 667, 42, 778, 21, 447, 13, 25, 11, 2035, 11702, 16, 192, 67, 14, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "===> x_data shape :  (729, 256)\n",
      "===> y_data shape :  (729, 3)\n",
      "\n",
      "\n",
      "===> 검증데이터 샘플 출력 및 전처리 시작 <===\n",
      "    label                                           sentence\n",
      "729     A  미라클 프루트를 포함하는 스테비아 감미 음료에 대한 맛 개선 스테비아 성분, 미라클...\n",
      "730     C  폴리머 물품 표면 상에 전기-전도성 트레이스들의 형성을 위한 방법 본 발명은 금속화...\n",
      "731     B  광조사 장치 본 발명은, 피처리체의 반송 속도에 상관없이, 높은 안정성으로 광세정을...\n",
      "732     B  제습제 또는 흡습제용 내부 비닐 포장지의 관통홀 제조장치 본 발명은 권취롤에서 공급...\n",
      "733     A  동식물 원료로부터의 향료 조성물의 제조 방법 및 동식물 원료로부터의 향기 회수 장치...\n",
      "734     C  헛개식초분말의 제조방법 및 상기 방법으로 제조된 헛개식초분말 본 발명은 헛개 추출물...\n",
      "735     A  홍삼 진세노사이드와 미생물 마늘발효에서 유래된 글루타치온 성분이 함유된 혈행개선효과...\n",
      "736     B  파티네이션되거나 파티나-준비된 금속 트랜잭션 카드들 및 제조 공정들 본 발명은 권한...\n",
      "737     A  단감 주스 및 이의 제조방법 본 발명은 단감 주스 및 이의 제조방법에 관한 것으로,...\n",
      "738     C  핫 스탬프용 합금화 Al 도금 강판 및 핫 스탬프 부재 본 발명은, 표면에, A상(...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "데이터 전처리 진행중: 81it [00:00, 134.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> 전처리 결과 출력 <===\n",
      "===> tokens sample :  ['[CLS]', '미', '##라', '##클', '프', '##루', '##트', '를', '포함', '하', '는', '스', '테', '비아', '감미', '음료', '에', '대한', '맛', '개선', '스', '테', '비아', '성분', ',', '미', '##라', '##클', '프', '##루', '##트', '성분', '및', '음료', '를', '함유', '하', '는', '조성물', '.', '미', '##라', '##클', '프', '##루', '##트', '를', '포함', '하', '는', '스', '테', '비아', '감미', '음료', '의', '제조', '방법', '.', '[SEP]']\n",
      "===> indices sample :  [5, 222, 20362, 20540, 122, 20513, 20333, 16, 79, 12, 11, 94, 360, 3623, 11244, 3599, 10, 241, 5044, 1219, 94, 360, 3623, 622, 8, 222, 20362, 20540, 122, 20513, 20333, 622, 44, 3599, 16, 515, 12, 11, 454, 14, 222, 20362, 20540, 122, 20513, 20333, 16, 79, 12, 11, 94, 360, 3623, 11244, 3599, 9, 216, 157, 14, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "===> x_data shape :  (81, 256)\n",
      "===> y_data shape :  (81, 3)\n",
      "\n",
      "\n",
      "===> 평가데이터 샘플 출력 및 전처리 시작 <===\n",
      "    label                                           sentence\n",
      "810     C  방향성 전자 강판 및 방향성 전자 강판의 제조 방법 본 발명의 일 양태에 관한 방향...\n",
      "811     C  용선의 예비 처리 방법과 극저인강의 제조 방법 본 발명은, 용선의 예비 처리에 있어...\n",
      "812     C  EM 발효액을 이용한 발효 촉진용 EM 지구사랑 발효기 시스템 본 발명은 EM(Ef...\n",
      "813     B  물과 공기압을 이용하여 상수도 배관 내 스케일과 슬라임과 이물질을 제거하는 휴대용 ...\n",
      "814     C  금속 코팅된 강철 스트립 본 발명은 0.3-10 중량%의 Mg 및 0.005-0.2...\n",
      "815     C  스프릿 원단 전처리 장치 및 방법 본 발명은 스프릿 원단 전처리 장치 및 방법에 관...\n",
      "816     A  치킨텐더용 닭고기 가공식품의 제조방법 및 이로 제조된 치킨텐더용 닭고기 가공식품 본...\n",
      "817     A  야로우 신선-식물 압착 주스 농축물, 생산, 및 용도 본 발명은 야로우 신선 식물 ...\n",
      "818     B  특성이 서로 다른 복수(2이상 다수)개의 권역별 정보매체들의 편집방법 또는정보제공방...\n",
      "819     B  스케일 형성 방지 기능을 갖는 세정기 본 발명은 스케일 형성 방지 기능을 갖는 세정...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "데이터 전처리 진행중: 90it [00:00, 119.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> 전처리 결과 출력 <===\n",
      "===> tokens sample :  ['[CLS]', '방향', '성', '전자', '강판', '및', '방향', '성', '전자', '강판', '의', '제조', '방법', '본', '발명', '의', '일', '양태', '에', '관한', '방향', '성', '전자', '강판', '은', ',', '강판', '과', ',', '강판', '상', '에', '배치', '된', 'Si', '및', 'O', '를', '포함', '하', '는', '중간층', '과', ',', '중간층', '상', '에', '배치', '된', '절연', '피막', '을', '갖', '는', '방향', '성', '전자', '강판', '이', '며', ',', '중간층', '이', '금속', '인', '##화물', '을', '함유', '하', '고', ',', '중간층', '의', '층', '두께', '가', '4', 'nm', '이상', '이', '고', ',', '금속', '인', '##화물', '의', '존재', '량', '이', ',', '중간층', '의', '단면', '에', '있', '어서', '의', '단면', '면적', '률', '로', '1', '내지', '30', '[UNK]', '이', '다', '.', '[SEP]']\n",
      "===> indices sample :  [5, 280, 106, 403, 3508, 44, 280, 106, 403, 3508, 9, 216, 157, 58, 77, 9, 70, 2239, 10, 439, 280, 106, 403, 3508, 32, 8, 3508, 55, 8, 3508, 17, 10, 394, 30, 1235, 44, 318, 16, 79, 12, 11, 7377, 55, 8, 7377, 17, 10, 394, 30, 626, 4287, 15, 237, 11, 280, 106, 403, 3508, 13, 134, 8, 7377, 13, 412, 53, 1503, 15, 515, 12, 34, 8, 7377, 9, 151, 645, 22, 72, 1071, 208, 13, 34, 8, 412, 53, 1503, 9, 671, 5355, 13, 8, 7377, 9, 631, 10, 25, 125, 9, 631, 1904, 1593, 37, 19, 200, 532, 4, 13, 18, 14, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "===> x_data shape :  (90, 256)\n",
      "===> y_data shape :  (90, 3)\n",
      "===> 라벨 사이즈 :  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# KorPat Tokenier 선언\n",
    "tokenizer = Tokenizer(vocab_path=vocab_path, cased=True)\n",
    "\n",
    "# 필요 데이터셋 로드\n",
    "train_data, dev_data, test_data = dataset_load(dataset_path)\n",
    "\n",
    "# 모든 데이터셋 전처리\n",
    "print(\"===> 학습데이터 샘플 출력 및 전처리 시작 <===\")\n",
    "print(train_data[:10])\n",
    "train_tokens, train_x, train_y = preprocessing_dataset(train_data)\n",
    "\n",
    "print(\"\\n\\n===> 검증데이터 샘플 출력 및 전처리 시작 <===\")\n",
    "print(dev_data[:10])\n",
    "dev_tokens, dev_x, dev_y = preprocessing_dataset(dev_data)\n",
    "\n",
    "print(\"\\n\\n===> 평가데이터 샘플 출력 및 전처리 시작 <===\")\n",
    "print(test_data[:10])\n",
    "test_tokens, test_x, test_y = preprocessing_dataset(test_data)\n",
    "\n",
    "# 라벨의 크기 정의\n",
    "label_size = train_y.shape[1]\n",
    "print(\"===> 라벨 사이즈 : \", label_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer \"bert\" (type BertModelLayer).\n\nLayer input_spec must be an instance of InputSpec. Got: InputSpec(shape=(None, 256, 768), ndim=3)\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 256), dtype=int32)\n  • mask=None\n  • training=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f7daa401f9a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# 입력레이어와 BERT 레이어 연결\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mbert_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml_bert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/bert/model.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0moutput\u001b[0m           \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoders_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m   \u001b[0;31m# [B, seq_len, hidden_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/bert/transformer.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInputSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;31m# create all transformer encoder sub-layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer \"bert\" (type BertModelLayer).\n\nLayer input_spec must be an instance of InputSpec. Got: InputSpec(shape=(None, 256, 768), ndim=3)\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 256), dtype=int32)\n  • mask=None\n  • training=None"
     ]
    }
   ],
   "source": [
    "# 분류 모델 네트워크 정의, ※ MirroredStrategy (분산처리 포함)\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "with mirrored_strategy.scope():\n",
    "    # 입력 레이어 생성\n",
    "    input_ids  = keras.layers.Input(shape=(MAX_SEQ_LEN,), dtype='int32')\n",
    "    \n",
    "    # BERT 언어모델 레이어 생성\n",
    "    bert_params = bert.params_from_pretrained_ckpt(pretreind_model_dir)\n",
    "    l_bert = bert.BertModelLayer.from_params(bert_params, name=\"bert\")\n",
    "    \n",
    "    # 입력레이어와 BERT 레이어 연결\n",
    "    bert_output = l_bert(input_ids) \n",
    "    print(\"bert shape\", bert_output.shape)\n",
    "    \n",
    "    # BERT 출력 중 Context 정보가 담긴, [CLS] 토큰 정보를 추출\n",
    "    cls_out = keras.layers.Lambda(lambda seq: seq[:, 0, :])(bert_output)\n",
    "    \n",
    "    # 최종 분류를 위한 클래스 개수로 구성된 Dense 레이어를 연결\n",
    "    outputs = Dense(units=3, activation='softmax')(cls_out) #    outputs = Dense(units=label_size, activation='softmax')(cls_out) \n",
    "    \n",
    "    # 모델 빌딩\n",
    "    model = keras.Model(inputs=input_ids, outputs=outputs)\n",
    "    model.build(input_shape=(None, MAX_SEQ_LEN))\n",
    "    \n",
    "    # BERT 언어모델의 초기 가중치 로드\n",
    "    bert.load_stock_weights(l_bert, checkpoint_path)\n",
    "    \n",
    "    # 모델 컴파일 과정\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=LR),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "# 모델 요약 출력\n",
    "model.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-da2996e0bc0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 모델 학습 시작\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# 모델 학습 시작\n",
    "history = model.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(dev_x, dev_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 및 테스트 데이터를 이용한 평가\n",
    "model.save(save_model_path)\n",
    "eval_result = model.evaluate(test_x, test_y)\n",
    "\n",
    "print('\\n===> 평가 결과 출력')\n",
    "print(\"Accuracy : %.4f\" % (eval_result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
